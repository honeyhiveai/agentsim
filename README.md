# Realign

`realign` is a simulation based evaluation framework for multi-step agents.

## what is `realign`?
`realign` helps you iterate on your LLM aplications faster by:
1. Simulating synthetic test cases or trajectories for your application
2. Run evaluations on your application outputs to measure their quality
3. Help you iterate on your application using the evaluations

## why build `realign`?
there are many LLM eval frameworks that are already out there.
so why are we building another one?

1. **Simulating Synthetic Test Cases*

For multi-step agents, it is hard to generate diverse test cases that cover all edge cases and test paths.

Realign's synthetic dataset toolkit helps you augment or regenerate diverse test cases for your application.

By running your application in a simulated environment quickly, you can understand your agent's behavior and improve it.

2. **Run Evaluations**

If you can't measure your LLM applications, you can't improve them.

Realign's evaluation toolkit helps you run evaluations on your application outputs to measure their quality.

You can also run evaluations after each simulation and pull up all the runs which had interesting scores.

3. **Iterate Faster on your Application**

We help you improve your application using insights from your simulations and evaluations by ...?

## Quickstart




